# ğŸ“ ExtensaoGPT

A backend application that uses the OpenAI API to extract the **most important topics** from educational YouTube videos. Designed for students, researchers, and content creators who want a fast, AI-powered summary of what a video covers.

---

## ğŸŒ Overview

**ExtensaoGPT** powers a browser extension popup. The workflow is simple: you select a YouTube video (and how many topics you want), and the backend handles the heavy lifting:

1.  **Downloads** the audio from YouTube.
2.  **Transcribes** it using OpenAIâ€™s Speech-to-Text (Whisper).
3.  **Extracts** the top *X* most important topics using GPT-4.
4.  **Returns** a clean JSON response ready to render in the UI.

---

## ğŸš€ Features

* ğŸ”— **YouTube Audio Download:** Uses `yt-dlp` to fetch the best available audio.
* ğŸ™ï¸ **Automatic Transcription:** Leverages OpenAI Audio API (`whisper-1`).
* ğŸ§  **Topic Extraction:** Uses **GPT-4** to summarize content into a configurable number of topics (5, 7, 10, etc.).
* âš™ï¸ **Optimized Pipeline:**
    * Audio splitting with `ffmpeg`.
    * Parallel segment transcription for long videos.
    * Chunk-based topic extraction and consolidation.
* ğŸ§ª **JSON API:** Returns structured data for easy integration with browser extensions.

---

## ğŸ› ï¸ Tech Stack

* **Python 3**
* **Flask** + **Flask-CORS** (HTTP API)
* **OpenAI API** (`whisper-1` & `gpt-4`)
* **yt-dlp** (Media download)
* **ffmpeg** (Audio segmentation/conversion)
* **python-dotenv** (Environment variable management)

---

## ğŸ“ Project Structure

```text
ExtensaoGPT/
â”œâ”€ Back/
â”‚  â”œâ”€ main.py            # Flask server (entrypoint)
â”‚  â”œâ”€ transcricao.py     # Download + segmentation + transcription
â”‚  â”œâ”€ topicos.py         # GPT-4 topic extraction
â”‚  â”œâ”€ .env               # API Keys (not committed)
â”‚  â””â”€ requirements.txt   # Python dependencies
â””â”€ Front/
   â”œâ”€ manifest.json      # Extension manifest
   â”œâ”€ popup.html         # Extension UI
   â”œâ”€ popup.js           # Client-side logic
   â””â”€ style.css          # Styling
```

---

## âš™ï¸ Installation & Setup

### 1. Clone the repository
```bash
git clone <your_repo_url>
cd ExtensaoGPT/Back
```

### 2. Create a virtual environment (Optional)
```bash
python -m venv .venv

# Windows
.venv\Scripts\Activate.ps1
# Mac/Linux
source .venv/bin/activate
```

### 3. Install Python dependencies
```bash
pip install flask flask-cors openai python-dotenv yt-dlp
```

### 4. Install FFmpeg
**Required:** You must have a working `ffmpeg` executable for audio segmentation.
1.  Download an ffmpeg essentials build.
2.  Add the `bin` folder to your system **PATH**, OR configure the full path in `transcricao.py`.

### 5. Configure environment variables
Create a `.env` file in the `Back/` folder:
```ini
OPENAI_API_KEY=your_openai_api_key_here
```

---

## â–¶ï¸ Running the Backend

From the `Back/` folder:

```bash
python main.py
```

* **Server runs at:** `http://127.0.0.1:5000`
* **Endpoint:** `POST /process`

---

## ğŸ”Œ API Endpoint

### `POST /process`

**Request Body:**
```json
{
  "video_url": "[https://www.youtube.com/watch?v=XXXX](https://www.youtube.com/watch?v=XXXX)",
  "num_topicos": 7
}
```

| Parameter | Type | Description |
| :--- | :--- | :--- |
| `video_url` | string | The full YouTube video URL. |
| `num_topicos` | int | (Optional) Number of topics to extract. Defaults to 7. |

**Response (Success):**
```json
{
  "topics": "1. Topic one\n2. Topic two\n3. Topic three\n..."
}
```

**Response (Error):**
```json
{
  "error": "Error message details"
}
```

---

## ğŸ§  How It Works (Pipeline)

1.  **Download:** `transcricao.py` uses `yt-dlp` to download audio to `work/audio.<ext>`.
2.  **Segment & Transcribe:**
    * Splits audio into segments using `ffmpeg`.
    * Transcribes segments in parallel (`ThreadPoolExecutor`) using `whisper-1`.
    * Concatenates segments into a full text string.
3.  **Extract Topics:** `topicos.py` chunks the text (to manage token limits), runs GPT-4 on each chunk, and consolidates the results into a final numbered list.

---

## ğŸ§© Possible Improvements

- [ ] Add caching by YouTube Video ID (avoid re-processing).
- [ ] Support for multiple output languages.
- [ ] Stream progress updates (Download â†’ Transcribe â†’ Summarize) via WebSocket.

<br>
<br>

---
---

<br>
<br>

# ğŸ“ ExtensaoGPT (PortuguÃªs)

Uma aplicaÃ§Ã£o backend que utiliza a API da OpenAI para extrair os **principais tÃ³picos** de vÃ­deos educacionais do YouTube. Ideal para estudantes, pesquisadores e criadores de conteÃºdo que desejam um resumo rÃ¡pido e inteligente dos vÃ­deos assistidos.

---

## ğŸŒ VisÃ£o Geral

O **ExtensaoGPT** Ã© o backend que alimenta uma extensÃ£o de navegador. O fluxo de uso Ã© simples: vocÃª seleciona um vÃ­deo do YouTube (e quantos tÃ³picos deseja), e o backend realiza o seguinte processo:

1.  **Baixa** o Ã¡udio do YouTube.
2.  **Transcreve** o conteÃºdo com o Speech-to-Text da OpenAI (Whisper).
3.  **Extrai** os *X* tÃ³picos mais importantes usando o GPT-4.
4.  **Retorna** uma resposta em JSON pronta para ser exibida na extensÃ£o.

---

## ğŸš€ Funcionalidades

* ğŸ”— **Download de Ãudio:** Utiliza `yt-dlp` para baixar o melhor Ã¡udio disponÃ­vel.
* ğŸ™ï¸ **TranscriÃ§Ã£o AutomÃ¡tica:** Utiliza a API `whisper-1` da OpenAI.
* ğŸ§  **ExtraÃ§Ã£o de TÃ³picos:** Usa o **GPT-4** para identificar pontos chave (configurÃ¡vel: 5, 7, 10 tÃ³picos, etc.).
* âš™ï¸ **Pipeline Otimizada:**
    * SegmentaÃ§Ã£o de Ã¡udio com `ffmpeg`.
    * TranscriÃ§Ã£o paralela de segmentos para vÃ­deos longos.
    * ConsolidaÃ§Ã£o de tÃ³picos em blocos.
* ğŸ§ª **API JSON:** Retorno estruturado para fÃ¡cil integraÃ§Ã£o com frontends.

---

## ğŸ› ï¸ Tecnologias Utilizadas

* **Python 3**
* **Flask** + **Flask-CORS** (API HTTP)
* **OpenAI API** (`whisper-1` e `gpt-4`)
* **yt-dlp** (Download de mÃ­dia)
* **ffmpeg** (SegmentaÃ§Ã£o e conversÃ£o de Ã¡udio)
* **python-dotenv** (Gerenciamento de variÃ¡veis de ambiente)

---

## ğŸ“ Estrutura do Projeto

```text
ExtensaoGPT/
â”œâ”€ Back/
â”‚  â”œâ”€ main.py            # Servidor Flask (ponto de entrada)
â”‚  â”œâ”€ transcricao.py     # Download + segmentaÃ§Ã£o + transcriÃ§Ã£o
â”‚  â”œâ”€ topicos.py         # ExtraÃ§Ã£o de tÃ³picos com GPT-4
â”‚  â”œâ”€ .env               # Chave da API (nÃ£o versionado)
â”‚  â””â”€ requirements.txt   # DependÃªncias Python
â””â”€ Front/
   â”œâ”€ manifest.json      # Manifesto da extensÃ£o
   â”œâ”€ popup.html         # UI do popup
   â”œâ”€ popup.js           # LÃ³gica do cliente
   â””â”€ style.css          # Estilos
```

---

## âš™ï¸ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

### 1. Clonar o repositÃ³rio
```bash
git clone <seu_repo_url>
cd ExtensaoGPT/Back
```

### 2. Criar ambiente virtual (Opcional)
```bash
python -m venv .venv

# Windows
.venv\Scripts\Activate.ps1
# Mac/Linux
source .venv/bin/activate
```

### 3. Instalar dependÃªncias
```bash
pip install flask flask-cors openai python-dotenv yt-dlp
```

### 4. Instalar FFmpeg
**ObrigatÃ³rio:** Ã‰ necessÃ¡rio ter o executÃ¡vel do `ffmpeg` para a segmentaÃ§Ã£o de Ã¡udio.
1.  Baixe um build do ffmpeg.
2.  Adicione a pasta `bin` ao **PATH** do sistema, OU configure o caminho absoluto no arquivo `transcricao.py`.

### 5. Configurar variÃ¡veis de ambiente
Crie um arquivo `.env` na pasta `Back/`:
```ini
OPENAI_API_KEY=sua_chave_da_openai_aqui
```

---

## â–¶ï¸ Executando o Backend

A partir da pasta `Back/`:

```bash
python main.py
```

* **Servidor roda em:** `http://127.0.0.1:5000`
* **Endpoint:** `POST /process`

---

## ğŸ”Œ Endpoint da API

### `POST /process`

**Corpo da RequisiÃ§Ã£o (JSON):**
```json
{
  "video_url": "[https://www.youtube.com/watch?v=XXXX](https://www.youtube.com/watch?v=XXXX)",
  "num_topicos": 7
}
```

| ParÃ¢metro | Tipo | DescriÃ§Ã£o |
| :--- | :--- | :--- |
| `video_url` | string | URL completa do vÃ­deo do YouTube. |
| `num_topicos` | int | (Opcional) Quantidade de tÃ³picos a extrair. PadrÃ£o: 7. |

**Resposta (Sucesso):**
```json
{
  "topics": "1. TÃ³pico um\n2. TÃ³pico dois\n3. TÃ³pico trÃªs\n..."
}
```

**Resposta (Erro):**
```json
{
  "error": "Mensagem detalhada do erro"
}
```

---

## ğŸ§  Como Funciona (Pipeline)

1.  **Download:** O script `transcricao.py` usa o `yt-dlp` para baixar o Ã¡udio em `work/audio.<ext>`.
2.  **SegmentaÃ§Ã£o e TranscriÃ§Ã£o:**
    * O Ã¡udio Ã© dividido em partes menores usando `ffmpeg`.
    * Cada parte Ã© transcrita em paralelo (`ThreadPoolExecutor`) via `whisper-1`.
    * Os segmentos sÃ£o concatenados numa string final.
3.  **ExtraÃ§Ã£o de TÃ³picos:** O script `topicos.py` divide o texto em *chunks* (para respeitar limites de tokens), roda o GPT-4 em cada parte e consolida o resultado numa lista final.

---

## ğŸ§© PossÃ­veis Melhorias

- [ ] Cache por ID do vÃ­deo (evitar reprocessamento).
- [ ] Suporte para mÃºltiplos idiomas de saÃ­da.
- [ ] Streaming de progresso (Download â†’ TranscriÃ§Ã£o â†’ Resumo) via WebSocket.
