# ğŸ“ ExtensaoGPT

A backend application that uses the OpenAI API to extract the **most important topics** from educational YouTube videos. Designed for students, researchers, and content creators who want a fast, AI-powered overview of what a video covers.

> ğŸ” **Security note:** never commit API keys. If you ever pasted an API key in a public place, rotate it immediately.

---

## ğŸŒ Overview

**ExtensaoGPT** powers a browser extension popup. The workflow is simple: you select a YouTube video (and how many topics you want), and the backend handles the heavy lifting:

1. **Starts an async job** for a YouTube video (and desired topic count).
2. **Downloads** the audio from YouTube.
3. **Transcribes** it using OpenAIâ€™s **speech-to-text (Audio Transcriptions)** API (model configurable).
4. **Extracts** the top *X* most important topics using a GPT model (e.g., GPT-4).
5. **Tracks progress** via a job status endpoint so the UI can keep updating even if the popup closes.

---

## ğŸš€ Features

* ğŸ”— **YouTube Audio Download:** Uses `yt-dlp` to fetch the best available audio (with multiple extraction strategies for improved reliability).
* ğŸ™ï¸ **Automatic Transcription:** Uses OpenAI **Audio Transcriptions (speech-to-text)** API (transcription model configurable via environment variables).
* ğŸ§  **Topic Extraction:** Uses **GPT** (e.g., GPT-4) to summarize content into a configurable number of topics (5, 7, 10, etc.).
* âš™ï¸ **Optimized Pipeline:**
  * Audio splitting + conversion with `ffmpeg` (segments reduce request size and improve stability).
  * Configurable transcription concurrency and retry policy.
  * Chunk-based topic extraction and consolidation.
* ğŸ§ª **Async Job API + Progress:**
  * `POST /process` returns **202 + job_id** immediately.
  * `GET /status/<job_id>` returns status (`queued`, `running`, `done`, `error`), progress %, and results.
* ğŸ—ƒï¸ **Caching (optional):** Results can be cached by `(video_url, topic_budget)` to avoid recomputation on repeated requests.
* ğŸ§© **Extension-friendly JSON:** Designed for easy integration with a browser extension UI.

---

## ğŸ› ï¸ Tech Stack

* **Python 3**
* **Flask** + **Flask-CORS** (HTTP API)
* **OpenAI API**
  * **Audio Transcriptions (speech-to-text)**
  * **Chat Completions** (topic extraction)
* **yt-dlp** (Media download)
* **ffmpeg** (Audio segmentation/conversion)
* **python-dotenv** (Environment variable management)

---

## ğŸ“ Project Structure

```text
ExtensaoGPT/
â”œâ”€ Back/
â”‚  â”œâ”€ main.py            # Flask server (async job API)
â”‚  â”œâ”€ transcricao.py     # Download + segmentation + transcription
â”‚  â”œâ”€ topicos.py         # GPT topic extraction
â”‚  â”œâ”€ .env               # API keys and settings (not committed)
â”‚  â”œâ”€ requirements.txt   # Python dependencies
â”‚  â””â”€ work/
â”‚     â”œâ”€ cache/          # Cached results (optional)
â”‚     â””â”€ jobs.json       # Persisted job status (best-effort)
â””â”€ Front/
   â”œâ”€ manifest.json      # Extension manifest
   â”œâ”€ popup.html         # Extension UI
   â”œâ”€ popup.js           # Client-side logic (starts job + polls status)
   â””â”€ style.css          # Styling
```

---

## âš™ï¸ Installation & Setup

### 1. Clone the repository
```bash
git clone <your_repo_url>
cd ExtensaoGPT/Back
```

### 2. Create a virtual environment (Optional)
```bash
python -m venv .venv

# Windows
.venv\Scripts\Activate.ps1
# Mac/Linux
source .venv/bin/activate
```

### 3. Install Python dependencies

Preferred:
```bash
pip install -r requirements.txt
```

Or manually:
```bash
pip install flask flask-cors openai python-dotenv yt-dlp
```

### 4. Install FFmpeg

**Required:** You must have a working `ffmpeg` executable for audio segmentation/conversion.

1. Download an ffmpeg build.
2. Add the `bin` folder to your system **PATH**, OR set the full path using `FFMPEG_PATH` in `.env`.

### 5. Configure environment variables

Create a `.env` file in the `Back/` folder:
```ini
OPENAI_API_KEY=your_openai_api_key_here

# Optional (recommended)
FFMPEG_PATH=/path/to/ffmpeg

# Transcription behavior
TRANSCRIBE_MODEL=gpt-4o-mini-transcribe
TRANSCRIBE_SEGMENT_SECONDS=480
TRANSCRIBE_WORKERS=1
TRANSCRIBE_MAX_RETRIES=6

# Backend concurrency
MAX_JOBS=2

# Optional: helps yt-dlp on restricted videos (chrome|edge|firefox)
YTDLP_COOKIES_FROM_BROWSER=chrome
```

---

## â–¶ï¸ Running the Backend

From the `Back/` folder:

```bash
python main.py
```

* **Server runs at:** `http://127.0.0.1:5000`
* **Health check:** `GET /health`
* **Start job:** `POST /process`
* **Check status/results:** `GET /status/<job_id>`

---

## ğŸ”Œ API Endpoint

### `POST /process` (start async job)

**Request Body:**
```json
{
  "video_url": "https://www.youtube.com/watch?v=XXXX",
  "num_topicos": 7
}
```

| Parameter | Type | Description |
| :--- | :--- | :--- |
| `video_url` | string | The full YouTube video URL. |
| `num_topicos` | int | (Optional) Number of topics to extract. Defaults to 7. |

**Response (Accepted - 202):**
```json
{
  "job_id": "e9a1675f-3452-4560-afab-9f9642529740",
  "status": "queued"
}
```

### `GET /status/<job_id>` (poll job status)

**Response (Running):**
```json
{
  "status": "running",
  "progress": 35,
  "step": "transcribing",
  "video_url": "https://www.youtube.com/watch?v=XXXX",
  "num_topics": 7
}
```

**Response (Done):**
```json
{
  "status": "done",
  "progress": 100,
  "topics": "1. Topic one\n2. Topic two\n3. Topic three\n...",
  "step": "done"
}
```

**Response (Error):**
```json
{
  "status": "error",
  "progress": 100,
  "error": "Error message details"
}
```

---

## ğŸ§  How It Works (Pipeline)

1. **Start job:** `main.py` receives `POST /process`, creates a `job_id`, and returns immediately (`HTTP 202`).
2. **Download:** `transcricao.py` uses `yt-dlp` to download audio to `work/audio.<ext>` (optional cookies for restricted videos).
3. **Segment & Transcribe:**
   * Splits/converts audio into segments using `ffmpeg`.
   * Transcribes each segment using OpenAI **Audio Transcriptions (speech-to-text)**.
   * Supports configurable workers and retry/backoff.
4. **Extract Topics:** `topicos.py` chunks the text (to manage token limits), extracts candidate topics, and consolidates the results into a final numbered list.

---

## ğŸ§© Possible Improvements

- [ ] Add caching by YouTube Video ID (avoid re-processing).
- [ ] Support for multiple output languages.
- [ ] Stream progress updates (Download â†’ Transcribe â†’ Summarize) via WebSocket / SSE (instead of polling).
- [ ] Add optional timestamps per topic for better navigation.
- [ ] Add a deployable mode (Docker + production WSGI server).

<br>
<br>

---
---

<br>
<br>

# ğŸ“ ExtensaoGPT (PortuguÃªs)

Uma aplicaÃ§Ã£o backend que utiliza a API da OpenAI para extrair os **principais tÃ³picos** de vÃ­deos educacionais do YouTube. Ideal para estudantes, pesquisadores e criadores de conteÃºdo que desejam um resumo rÃ¡pido e inteligente do que um vÃ­deo aborda.

> ğŸ” **Nota de seguranÃ§a:** nunca versione chaves de API. Se uma chave foi exposta, faÃ§a a rotaÃ§Ã£o imediatamente.

---

## ğŸŒ VisÃ£o Geral

O **ExtensaoGPT** Ã© o backend que alimenta uma extensÃ£o de navegador. O fluxo de uso Ã© simples: vocÃª seleciona um vÃ­deo do YouTube (e quantos tÃ³picos deseja), e o backend realiza o seguinte processo:

1. **Inicia um job assÃ­ncrono** para o vÃ­deo do YouTube (e a quantidade de tÃ³picos).
2. **Baixa** o Ã¡udio do YouTube.
3. **Transcreve** usando a API de **Audio Transcriptions (speech-to-text)** da OpenAI (modelo configurÃ¡vel).
4. **Extrai** os *X* tÃ³picos mais importantes usando um modelo GPT (ex.: GPT-4).
5. **Acompanha o progresso** via endpoint de status, permitindo que o job continue mesmo se o popup fechar.

---

## ğŸš€ Funcionalidades

* ğŸ”— **Download de Ãudio:** Utiliza `yt-dlp` para baixar o melhor Ã¡udio disponÃ­vel (com mÃºltiplas estratÃ©gias para melhorar confiabilidade).
* ğŸ™ï¸ **TranscriÃ§Ã£o AutomÃ¡tica:** Utiliza a API de **Audio Transcriptions (speech-to-text)** da OpenAI (modelo configurÃ¡vel por variÃ¡veis de ambiente).
* ğŸ§  **ExtraÃ§Ã£o de TÃ³picos:** Usa um modelo **GPT** (ex.: GPT-4) para gerar tÃ³picos (configurÃ¡vel: 5, 7, 10 etc.).
* âš™ï¸ **Pipeline Otimizado:**
  * SegmentaÃ§Ã£o + conversÃ£o de Ã¡udio com `ffmpeg` (segmentos menores aumentam estabilidade).
  * ConcorrÃªncia e polÃ­tica de retry configurÃ¡veis na transcriÃ§Ã£o.
  * ExtraÃ§Ã£o de tÃ³picos por *chunks* e consolidaÃ§Ã£o final.
* ğŸ§ª **API AssÃ­ncrona com Progresso:**
  * `POST /process` retorna **202 + job_id** imediatamente.
  * `GET /status/<job_id>` retorna status (`queued`, `running`, `done`, `error`), progresso (%) e resultados.
* ğŸ—ƒï¸ **Cache (opcional):** pode armazenar resultados por `(video_url, num_topicos)` para evitar reprocessamento.
* ğŸ§© **API JSON:** retorno estruturado para fÃ¡cil integraÃ§Ã£o com frontends/extensÃ£o.

---

## ğŸ› ï¸ Tecnologias Utilizadas

* **Python 3**
* **Flask** + **Flask-CORS** (API HTTP)
* **OpenAI API**
  * **Audio Transcriptions (speech-to-text)**
  * **Chat Completions** (extraÃ§Ã£o de tÃ³picos)
* **yt-dlp** (Download de mÃ­dia)
* **ffmpeg** (SegmentaÃ§Ã£o e conversÃ£o de Ã¡udio)
* **python-dotenv** (Gerenciamento de variÃ¡veis de ambiente)

---

## ğŸ“ Estrutura do Projeto

```text
ExtensaoGPT/
â”œâ”€ Back/
â”‚  â”œâ”€ main.py            # Servidor Flask (API assÃ­ncrona)
â”‚  â”œâ”€ transcricao.py     # Download + segmentaÃ§Ã£o + transcriÃ§Ã£o
â”‚  â”œâ”€ topicos.py         # ExtraÃ§Ã£o de tÃ³picos com GPT
â”‚  â”œâ”€ .env               # Chave e configs (nÃ£o versionado)
â”‚  â”œâ”€ requirements.txt   # DependÃªncias Python
â”‚  â””â”€ work/
â”‚     â”œâ”€ cache/          # Cache (opcional)
â”‚     â””â”€ jobs.json       # Status de jobs (best-effort)
â””â”€ Front/
   â”œâ”€ manifest.json      # Manifesto da extensÃ£o
   â”œâ”€ popup.html         # UI do popup
   â”œâ”€ popup.js           # LÃ³gica (inicia job + faz polling)
   â””â”€ style.css          # Estilos
```

---

## âš™ï¸ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

### 1. Clonar o repositÃ³rio
```bash
git clone <seu_repo_url>
cd ExtensaoGPT/Back
```

### 2. Criar ambiente virtual (Opcional)
```bash
python -m venv .venv

# Windows
.venv\Scripts\Activate.ps1
# Mac/Linux
source .venv/bin/activate
```

### 3. Instalar dependÃªncias

Preferencial:
```bash
pip install -r requirements.txt
```

Ou manual:
```bash
pip install flask flask-cors openai python-dotenv yt-dlp
```

### 4. Instalar FFmpeg

**ObrigatÃ³rio:** Ã‰ necessÃ¡rio ter o executÃ¡vel do `ffmpeg` para segmentar/converter Ã¡udio.

1. Baixe um build do ffmpeg.
2. Adicione a pasta `bin` ao **PATH** do sistema, OU defina o caminho absoluto usando `FFMPEG_PATH` no `.env`.

### 5. Configurar variÃ¡veis de ambiente

Crie um arquivo `.env` na pasta `Back/`:
```ini
OPENAI_API_KEY=sua_chave_da_openai_aqui

# Opcional (recomendado)
FFMPEG_PATH=/caminho/para/ffmpeg

TRANSCRIBE_MODEL=gpt-4o-mini-transcribe
TRANSCRIBE_SEGMENT_SECONDS=480
TRANSCRIBE_WORKERS=1
TRANSCRIBE_MAX_RETRIES=6

MAX_JOBS=2

YTDLP_COOKIES_FROM_BROWSER=chrome
```

---

## â–¶ï¸ Executando o Backend

A partir da pasta `Back/`:

```bash
python main.py
```

* **Servidor roda em:** `http://127.0.0.1:5000`
* **Health:** `GET /health`
* **Iniciar job:** `POST /process`
* **Consultar status/resultados:** `GET /status/<job_id>`

---

## ğŸ”Œ Endpoint da API

### `POST /process` (inicia job assÃ­ncrono)

**Corpo da RequisiÃ§Ã£o (JSON):**
```json
{
  "video_url": "https://www.youtube.com/watch?v=XXXX",
  "num_topicos": 7
}
```

| ParÃ¢metro | Tipo | DescriÃ§Ã£o |
| :--- | :--- | :--- |
| `video_url` | string | URL completa do vÃ­deo do YouTube. |
| `num_topicos` | int | (Opcional) Quantidade de tÃ³picos a extrair. PadrÃ£o: 7. |

**Resposta (Aceito - 202):**
```json
{
  "job_id": "e9a1675f-3452-4560-afab-9f9642529740",
  "status": "queued"
}
```

### `GET /status/<job_id>` (consulta status)

**Em execuÃ§Ã£o:**
```json
{
  "status": "running",
  "progress": 35,
  "step": "transcribing"
}
```

**ConcluÃ­do:**
```json
{
  "status": "done",
  "progress": 100,
  "topics": "1. TÃ³pico um\n2. TÃ³pico dois\n3. TÃ³pico trÃªs\n..."
}
```

**Erro:**
```json
{
  "status": "error",
  "progress": 100,
  "error": "Mensagem detalhada do erro"
}
```

---

## ğŸ§  Como Funciona (Pipeline)

1. **Inicia job:** `main.py` recebe `POST /process`, cria `job_id` e retorna imediatamente (HTTP 202).
2. **Download:** `transcricao.py` usa `yt-dlp` para baixar o Ã¡udio em `work/audio.<ext>` (cookies opcionais para vÃ­deos restritos).
3. **SegmentaÃ§Ã£o e TranscriÃ§Ã£o:**
   * Segmenta/converte o Ã¡udio em partes menores usando `ffmpeg`.
   * Transcreve cada segmento via OpenAI **Audio Transcriptions (speech-to-text)**.
   * ConcorrÃªncia e retry/backoff sÃ£o configurÃ¡veis.
4. **ExtraÃ§Ã£o de TÃ³picos:** `topicos.py` divide o texto em *chunks*, extrai tÃ³picos candidatos e consolida o resultado numa lista final numerada.

---

## ğŸ§© PossÃ­veis Melhorias

- [ ] Cache por ID do vÃ­deo (evitar reprocessamento).
- [ ] Suporte para mÃºltiplos idiomas de saÃ­da.
- [ ] Streaming de progresso (Download â†’ TranscriÃ§Ã£o â†’ Resumo) via WebSocket / SSE (em vez de polling).
- [ ] Timestamps por tÃ³pico para navegaÃ§Ã£o no vÃ­deo.
- [ ] Modo deploy (Docker + servidor WSGI em produÃ§Ã£o).
